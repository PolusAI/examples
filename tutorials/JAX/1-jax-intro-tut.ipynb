{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36427c62",
   "metadata": {},
   "source": [
    "## Section 0: JAX Readme - https://github.com/google/jax#installation\n",
    "\n",
    "Installation for Nvidia GPU on Linux X86_64 arch.\n",
    "\n",
    "Please follow the readme/documentation for information on alternative installation strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c5801",
   "metadata": {},
   "source": [
    "Installing the jax module and jaxlib with cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1db8c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Requirement already satisfied: jax[cuda12_pip] in /Users/akshat.saini/miniconda3/lib/python3.11/site-packages (0.4.18)\n",
      "Collecting jax[cuda12_pip]\n",
      "  Using cached jax-0.4.19-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /Users/akshat.saini/miniconda3/lib/python3.11/site-packages (from jax[cuda12_pip]) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/akshat.saini/miniconda3/lib/python3.11/site-packages (from jax[cuda12_pip]) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/akshat.saini/miniconda3/lib/python3.11/site-packages (from jax[cuda12_pip]) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /Users/akshat.saini/miniconda3/lib/python3.11/site-packages (from jax[cuda12_pip]) (1.11.3)\n",
      "INFO: pip is looking at multiple versions of jax[cuda12-pip] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached jax-0.4.18-py3-none-any.whl (1.7 MB)\n",
      "  Using cached jax-0.4.17-py3-none-any.whl (1.7 MB)\n",
      "  Using cached jax-0.4.16-py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of jax[cuda12-pip] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached jax-0.4.14.tar.gz (1.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25l|^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa2413",
   "metadata": {},
   "source": [
    "## Section 1: Understanding JAX Basics\n",
    "\n",
    "1.1 Importing JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077c1c5",
   "metadata": {},
   "source": [
    "1.2 Checking if JAX is utilizing the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b32b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a42a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = jax.devices()\n",
    "for device in devices:\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90789010",
   "metadata": {},
   "source": [
    "1.3 Number of CUDA devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10ae52",
   "metadata": {},
   "source": [
    "## Section 2: Computation using JAX \n",
    "\n",
    "2.1 JAX is designed to be compatible with NumPy, a widely used library for numerical operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9094a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "numpy_array = np.array([1, 2, 3])\n",
    "\n",
    "# Convert it to a JAX array\n",
    "jax_array = jnp.array(numpy_array)\n",
    "\n",
    "# Perform operations on the JAX array\n",
    "result = jax_array * 2\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bac40c",
   "metadata": {},
   "source": [
    "2.2 As can be seen above, we can use JAX in a similar way to NumPy, making it easy with NumPy to get started with JAX.\n",
    "\n",
    "2.3 One of the key features of JAX is its efficient automatic differentiation capabilities. This allows us to compute gradients effortlessly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad\n",
    "\n",
    "# Define a simple function\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 1\n",
    "\n",
    "# Compute the derivative of f with respect to x\n",
    "df_dx = grad(f)\n",
    "\n",
    "# Evaluate the derivative at x = 2\n",
    "result = df_dx(2)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260907b",
   "metadata": {},
   "source": [
    "2.4 JAX also allows us to compute higher-order gradients with ease, which is crucial for machine learning algorithms.\n",
    "\n",
    "2.5 JAX enables efficient vectorized computations, which can greatly accelerate numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that operates element-wise on an array\n",
    "def elementwise_func(x):\n",
    "    return x**2 + 3*x + 1\n",
    "\n",
    "# Apply the function to an array using JAX\n",
    "input_array = jnp.array([1, 2, 3, 4])\n",
    "result = elementwise_func(input_array)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
