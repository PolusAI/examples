{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9127c21-9ab0-4866-815e-01da11d7d48f",
   "metadata": {},
   "source": [
    "## Check if pytorch is currently used\n",
    "\n",
    "For each of the following it should be like this if pytorch is currently used:\n",
    "\n",
    "`torch.cuda.is_available()`\n",
    "\n",
    "True\n",
    "\n",
    " `torch.cuda.device_count()`\n",
    "\n",
    "1\n",
    "\n",
    "`torch.cuda.current_device()`\n",
    "\n",
    "0\n",
    "\n",
    "`torch.cuda.device(0)`\n",
    "\n",
    "<torch.cuda.device at 0x7efce0b03be0>\n",
    "\n",
    "`torch.cuda.get_device_name(0)`\n",
    "\n",
    "'GeForce GTX 950M'\n",
    "\n",
    "This tells us:\n",
    "\n",
    " - CUDA is available and can be used by one device.\n",
    " - Device 0 refers to the GPU ```GeForce GTX 950M```, and it is currently chosen by PyTorch.\n",
    "\n",
    "\n",
    "The code is in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a508eef-5eed-4f0e-bd26-ea3f595d229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294e054-7934-4707-b11a-9163115c4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa711c95-5137-47d7-a3d2-c189fae88555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d75c1c-4729-4f38-ae8e-f1631c0f7332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f3edfd74520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74cb61d-297e-4cf0-8a7b-976caf0a6bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec48ca-60a3-4d20-9da5-ba9833c01314",
   "metadata": {},
   "source": [
    "## Check for library version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8723bb1f-43da-44a3-8d5b-f947fe96a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c5b8e-6297-42c2-bb3a-52a929b2c12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science 0.1.5",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
