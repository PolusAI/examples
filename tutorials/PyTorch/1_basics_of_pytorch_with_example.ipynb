{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9389be16-ffac-4e9d-afe4-fb85018994a2",
   "metadata": {},
   "source": [
    "## Pytorch example 1.\n",
    "\n",
    "This is the example of Tensors.\n",
    "\n",
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later). The name “tensor” is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
    "\n",
    "Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don’t need it too often.\n",
    "\n",
    "[Link](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch_empty.ipynb) to the original source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b5367-ee9b-4252-9b45-a76367c97965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ece457-bf1f-4b2e-918e-67c75c84b9f3",
   "metadata": {},
   "source": [
    "PyTorch provides functions that are stochastic like generating random numbers. However, a very good practice is to setup your code to be reproducible with the exact same random numbers. This is why we set a seed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721410b-183b-43e6-8ac0-46938027aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # Setting the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aaa929-3a1b-49f3-844f-932de6641852",
   "metadata": {},
   "source": [
    "Let’s first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to ```call torch```.Tensor passing the desired shape as input argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1650b23-104a-43dd-91cf-c2158f5ee36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d477f9-06a5-442a-a46c-ad9912571744",
   "metadata": {},
   "source": [
    "The function ```torch.Tensor``` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
    "\n",
    "- ```torch.zeros```: Creates a tensor filled with zeros\n",
    "\n",
    "- ```torch.ones```: Creates a tensor filled with ones\n",
    "\n",
    "- ```torch.rand```: Creates a tensor with random values uniformly sampled between 0 and 1\n",
    "\n",
    "- ```torch.randn```: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
    "\n",
    "- ```torch.arange```: Creates a tensor containing the values \n",
    "\n",
    "-```torch.Tensor``` (input list): Creates a tensor from the list elements you provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba283f70-6132-412f-8bbe-d1de7b1b8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor from a (nested) list\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802dd61-9981-41a3-bde4-149adcde251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
    "x = torch.rand(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671be637-20d1-4cf0-800d-e050fe655e59",
   "metadata": {},
   "source": [
    "You can obtain the shape of a tensor in the same way as in numpy (```x.shape```), or using the ```.size``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8124cb2-57a9-40db-9331-69dcb7bc0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29eade-eb36-4048-965a-55c421f257bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensor to Numpy, and Numpy to Tensor\n",
    "\n",
    "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function ```torch.from_numpy```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae3bda-8923-4c72-9e38-fea11a21a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "\n",
    "print(\"Numpy array:\", np_arr)\n",
    "print(\"PyTorch tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3ca66-5bfc-4ae4-a39d-7da7aee9950a",
   "metadata": {},
   "source": [
    "To transform a PyTorch tensor back to a numpy array, we can use the function ```.numpy()``` on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55bb5c-0850-4f89-8435-bb7e44993bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.arange(4)\n",
    "np_arr = tensor.numpy()\n",
    "\n",
    "print(\"PyTorch tensor:\", tensor)\n",
    "print(\"Numpy array:\", np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a3efa-e4f9-4720-8970-23becbdd6415",
   "metadata": {},
   "source": [
    "Add two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec1aaf9-0e97-4501-84bb-ad85a4169012",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "y = x1 + x2\n",
    "\n",
    "print(\"X1\", x1)\n",
    "print(\"X2\", x2)\n",
    "print(\"Y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a602a42-d666-43d5-8085-1ddb67a6882f",
   "metadata": {},
   "source": [
    "Calling ```x1 + x2``` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor. We therefore change the values of ```x2``` without the chance to re-accessing the values of ```x2``` before the operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f7297-e961-4fff-afaa-91f738fe9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(2, 3)\n",
    "x2 = torch.rand(2, 3)\n",
    "print(\"X1 (before)\", x1)\n",
    "print(\"X2 (before)\", x2)\n",
    "\n",
    "x2.add_(x1)\n",
    "print(\"X1 (after)\", x1)\n",
    "print(\"X2 (after)\", x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18392bf0-60bf-4aa6-a65c-81a5baafc439",
   "metadata": {
    "tags": []
   },
   "source": [
    "In-place operations are usually marked with a underscore postfix (e.g. “add_” instead of “add”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b98fd-aa04-400d-a5d7-4644d9533bda",
   "metadata": {},
   "source": [
    "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), …). In PyTorch, this operation is called ```view```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d994b46-ce8a-4652-b4d1-c0c183d626bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(6)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21308e-d7e0-4396-be0d-4411060bc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c717828-5ba4-4bdf-97c5-e930a7794995",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b487b-b844-4ff5-97d3-0668d9e512a4",
   "metadata": {},
   "source": [
    "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector , which is transformed using a learned weight matrix . There are multiple ways and functions to perform matrix multiplication, some of which are listed below:\n",
    "\n",
    "- ```torch.matmul```: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as ```a @ b```, similar to numpy.\n",
    "\n",
    "- ```torch.mm```: Performs the matrix product over two matrices, but doesn’t support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
    "\n",
    "- ```torch.bmm```: Performs the matrix product with a support batch dimension. If the first tensor  is of shape (), and the second tensor  (), the output  is of shape (), and has been calculated by performing  matrix multiplications of the submatrices of  and : \n",
    "\n",
    "- ```torch.einsum```: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde79f6-ed11-4bc2-9fd7-1369872b4975",
   "metadata": {},
   "source": [
    "Usually, most commonly used is ```torch.matmul``` or ```torch.bmm```. However, below is a matrix multiplication with ```torch.matmul```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa16ac9-78bb-4fe4-ba7f-4effa7550deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d99de4-85c8-4ea1-911b-f5c7e3e53880",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
    "print(\"W\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6195fa-7857-4a45-a7a2-72e0755bc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163f48d-2597-4364-a7df-536249062d38",
   "metadata": {},
   "source": [
    "We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so the code is in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceb59c-3387-4e99-9741-5356378c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d257029-cb21-4948-a36b-22138ea38c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:, 1])   # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae9ebc-31ad-46a8-abce-045274e48cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0])      # First row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c493b8-a1de-4f74-acc3-24eaa4f00ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:2, -1]) # First two rows, last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc0b17-08bf-4307-bb2a-e9c3599afcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[1:3, :]) # Middle two rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science 0.1.5",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
