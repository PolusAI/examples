{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7f9167-ac5d-4a7c-8c37-d29d8617d1a8",
   "metadata": {},
   "source": [
    "## Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f95ac-a744-40b5-871c-7238986186a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0864f4-9a18-4f03-954f-c87db5b8f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eed8e6-da03-43be-b922-b4cfd4860ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters.\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc6d3e-d89e-4dd7-a4e3-9722e8464df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data.\n",
    "X = np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "              7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "Y = np.array([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "              2.827,3.465,1.65,2.904,2.42,2.94,1.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c81201-bd0d-4aec-9df5-336c5cb513a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and Bias, initialized randomly.\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Linear regression (Wx + b).\n",
    "def linear_regression(x):\n",
    "    return W * x + b\n",
    "\n",
    "# Mean square error.\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "# Stochastic Gradient Descent Optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f27789-19ab-458a-be28-0a39ba4e57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization():\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = linear_regression(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0994982-7d75-4091-9133-2bcd03212c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step in range(1, training_steps + 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization()\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = linear_regression(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "        print(\"step: %i, loss: %f, W: %f, b: %f\" % (step, loss, W.numpy(), b.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a4487-cef8-4840-a1a8-e1500d8c4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb515c-0301-47e8-8056-d2da98ac08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphic display\n",
    "plt.plot(X, Y, 'ro', label='Original data')\n",
    "plt.plot(X, np.array(W * X + b), label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c376c4-55b2-462b-bcc8-40a601078250",
   "metadata": {},
   "source": [
    "## Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a073b-2806-4d93-978d-53654cd16e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from keras import models, layers \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd251b4-41ce-48cf-a0fa-5a5f27e1858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and prepare the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7132b7-3e4d-4540-bdff-4ca2f0c2142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e049e5-f0a2-488d-851b-fa905104d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the neural network architecture\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images to 1D array\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer with 128 units and ReLU activation\n",
    "    layers.Dropout(0.2),  # Dropout layer to reduce overfitting\n",
    "    layers.Dense(10, activation ='softmax')  # Output layer with 10 units (one for each digit)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb291b-e60b-4e14-961f-12a232c2aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8ffab-dd9e-4626-acb9-0f24e0df266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b58df2a-f194-48fe-a468-b1e3406ba437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e0564-eca5-449e-9919-c993e72eea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an index\n",
    "sample_index = 24 \n",
    "\n",
    "sample = np.expand_dims(test_images[sample_index], axis=0)  # Add batch dimension\n",
    "\n",
    "prediction_random = model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d31a1d-4d46-4881-9b0e-31aae461040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(prediction_random)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science 0.1.8",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
